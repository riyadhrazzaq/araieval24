{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad2ee83-1043-4471-97c2-870d2f76c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from statistics import mean\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import jsonlines\n",
    "from transformers import BertModel, BertTokenizerFast, PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "ROOT = Path(\"../data/\")\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "LABELS = [\n",
    "    \"Appeal_to_Values\",\n",
    "    \"Loaded_Language\",\n",
    "    \"Consequential_Oversimplification\",\n",
    "    \"Causal_Oversimplification\",\n",
    "    \"Questioning_the_Reputation\",\n",
    "    \"Straw_Man\",\n",
    "    \"Repetition\",\n",
    "    \"Guilt_by_Association\",\n",
    "    \"Appeal_to_Hypocrisy\",\n",
    "    \"Conversation_Killer\",\n",
    "    \"False_Dilemma-No_Choice\",\n",
    "    \"Whataboutism\",\n",
    "    \"Slogans\",\n",
    "    \"Obfuscation-Vagueness-Confusion\",\n",
    "    \"Name_Calling-Labeling\",\n",
    "    \"Flag_Waving\",\n",
    "    \"Doubt\",\n",
    "    \"Appeal_to_Fear-Prejudice\",\n",
    "    \"Exaggeration-Minimisation\",\n",
    "    \"Red_Herring\",\n",
    "    \"Appeal_to_Popularity\",\n",
    "    \"Appeal_to_Authority\",\n",
    "    \"Appeal_to_Time\",\n",
    "]\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def parse_text(text, span_objs, tokenizer: PreTrainedTokenizerFast, labels):\n",
    "    assert isinstance(\n",
    "        tokenizer, PreTrainedTokenizerFast\n",
    "    ), \"Must be a sub-class of PreTrainedTokenizerFast\"\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_offsets_mapping=True,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "    label_encoding = [\n",
    "        [\n",
    "            0,\n",
    "        ]\n",
    "        * len(encoding.tokens())\n",
    "        for _ in labels\n",
    "    ]\n",
    "\n",
    "    for span in span_objs:\n",
    "        label_start, label_end, label = span[\"start\"], span[\"end\"], span[\"technique\"]\n",
    "        # l is for sequence number\n",
    "        for l, (token_start, token_end) in enumerate(encoding.offset_mapping):\n",
    "            if is_inside(token_start, token_end, label_start, label_end):\n",
    "                label_encoding[labels.index(label)][l] = 1\n",
    "\n",
    "    return encoding, label_encoding\n",
    "\n",
    "\n",
    "def is_inside(token_start, token_end, label_start, label_end):\n",
    "    return token_start >= label_start and token_end <= label_end\n",
    "\n",
    "\n",
    "def find_consecutive_trues(flags):\n",
    "    \"\"\"\n",
    "    This function takes an array of boolean flags and returns a list of ranges\n",
    "    of all consecutive true values.\n",
    "\n",
    "    Args:\n",
    "        flags: A list of boolean flags.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple represents a range of consecutive\n",
    "        true values. The tuple contains the starting and ending indices (inclusive)\n",
    "        of the range.\n",
    "    \"\"\"\n",
    "    ranges = []\n",
    "    start_idx = None\n",
    "    for i, flag in enumerate(flags):\n",
    "        if flag and start_idx is None:\n",
    "            start_idx = i\n",
    "        elif not flag and start_idx is not None:\n",
    "            ranges.append((start_idx, i - 1))\n",
    "            start_idx = None\n",
    "    if start_idx is not None:\n",
    "        ranges.append((start_idx, len(flags) - 1))\n",
    "    return ranges\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# flags = [1, 1, 0, 0, 1, 1, 1]\n",
    "# ranges = find_consecutive_trues(flags)\n",
    "# print(ranges)  # Output: [(0, 1), (3, 5)]\n",
    "\n",
    "\n",
    "\n",
    "def find_consecutive_trues(flags):\n",
    "    \"\"\"\n",
    "    This function takes an array of boolean flags and returns a list of ranges\n",
    "    of all consecutive true values.\n",
    "\n",
    "    Args:\n",
    "        flags: A list of boolean flags.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple represents a range of consecutive\n",
    "        true values. The tuple contains the starting and ending indices (inclusive)\n",
    "        of the range.\n",
    "    \"\"\"\n",
    "    ranges = []\n",
    "    start_idx = None\n",
    "    for i, flag in enumerate(flags):\n",
    "        if flag and start_idx is None:\n",
    "            start_idx = i\n",
    "        elif not flag and start_idx is not None:\n",
    "            ranges.append((start_idx, i - 1))\n",
    "            start_idx = None\n",
    "    if start_idx is not None:\n",
    "        ranges.append((start_idx, len(flags) - 1))\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def parse_sample(sample):\n",
    "    encoding, label_encoding = parse_text(\n",
    "        sample[\"text\"], sample[\"labels\"], tokenizer, LABELS\n",
    "    )\n",
    "    \n",
    "    return {\"encoding\": encoding, 'id': sample['id'], **encoding, \"labels\": label_encoding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847153a2-5067-4e84-9797-967e5cc6509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from statistics import mean\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import jsonlines\n",
    "from transformers import BertModel, BertTokenizerFast, PreTrainedTokenizerFast\n",
    "\n",
    "from datautil import LABELS\n",
    "\n",
    "label2id = {label: id for id, label in enumerate(LABELS)}\n",
    "id2label = {id: label for id, label in enumerate(LABELS)}\n",
    "\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "\n",
    "from typing import Optional, Union, Tuple\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "\n",
    "class CustomBertForTokenClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout\n",
    "            if config.classifier_dropout is not None\n",
    "            else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels.transpose(1, 2).float())\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac43f9fc-cbc5-444e-86ca-4d7772071d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jsonlines\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2fd10bd-8c76-4bcd-ab0f-a0309e028ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on /home/riyadh/codes/nlp/araieval_arabicnlp24/task1/src/../data/araieval24_task1_train.jsonl\n",
      "Validating on /home/riyadh/codes/nlp/araieval_arabicnlp24/task1/src/../data/araieval24_task1_dev.jsonl\n",
      "\n",
      "{'id': '7365', 'text': 'تحذيرات من حرب جديدة في حال فشل الانتخابات القادمة', 'labels': [{'start': 0, 'end': 50, 'technique': 'Appeal_to_Fear-Prejudice', 'text': 'تحذيرات من حرب جديدة في حال فشل الانتخابات القادمة'}, {'start': 11, 'end': 14, 'technique': 'Loaded_Language', 'text': 'حرب'}], 'type': 'tweet'}\n",
      "dict_keys(['encoding', 'id', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(ROOT)\n",
    "TRAIN_FILE = ROOT / \"araieval24_task1_train.jsonl\"\n",
    "DEV_FILE = ROOT / \"araieval24_task1_dev.jsonl\"\n",
    "\n",
    "print(f\"Training on {TRAIN_FILE.absolute()}\\nValidating on {DEV_FILE.absolute()}\\n\")\n",
    "\n",
    "with jsonlines.open(TRAIN_FILE) as jsonfile:\n",
    "    for obj in jsonfile:\n",
    "        print(obj)\n",
    "\n",
    "        parsed = parse_sample(obj)\n",
    "        print(parsed.keys())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3a1191-d94b-4398-80c5-3797a8a7db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DatasetFromJson(Dataset):\n",
    "  def __init__(self, data_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      data_path (str): Path to the JSONLines file containing map style data.\n",
    "    \"\"\"\n",
    "    self.data_path = data_path\n",
    "    self.data = []\n",
    "    self.raw = []\n",
    "    self._load_data()\n",
    "\n",
    "  def _load_data(self):\n",
    "    \"\"\"\n",
    "    Loads map style data from the JSONLines file.\n",
    "    \"\"\"\n",
    "    with open(self.data_path, \"r\") as f:\n",
    "      for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        self.data.append(parse_sample(data))\n",
    "        self.raw.append(data)\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    Returns the number of samples in the dataset.\n",
    "    \"\"\"\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    Retrieves a sample from the dataset.\n",
    "\n",
    "    Args:\n",
    "      idx (int): Index of the sample to retrieve.\n",
    "\n",
    "    Returns:\n",
    "      dict: A dictionary containing the map style features.\n",
    "    \"\"\"\n",
    "    return self.data[idx], self.raw[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8608cd34-9cbf-4507-90a0-1ef598a0b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DatasetFromJson(TRAIN_FILE)\n",
    "val_ds = DatasetFromJson(DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00e86d57-e7e4-4564-a142-44d539f72eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class CollateFn:\n",
    "    def __init__(self, return_raw=False):\n",
    "        self.data_collator = DataCollatorWithPadding(tokenizer, padding=True)\n",
    "        self.return_raw = return_raw\n",
    "        \n",
    "    def __call__(self, data: List):\n",
    "        # 'encoding', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'\n",
    "        encodings = []\n",
    "        raws = []\n",
    "        tensors = []\n",
    "        \n",
    "        for sample, raw in data:\n",
    "            encodings.append(sample['encoding'])\n",
    "            if self.return_raw:\n",
    "                raws.append(raw)\n",
    "            \n",
    "            del sample['encoding'], sample['id']\n",
    "            tensors.append(sample)\n",
    "\n",
    "        batch = self.data_collator(tensors)\n",
    "        \n",
    "        return {\n",
    "            'tensors': batch,\n",
    "            'encodings': encodings,\n",
    "            'raws': raws\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24b386c2-a0d6-4cd5-8250-e28318e5811a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m DataLoader(train_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, collate_fn \u001b[38;5;241m=\u001b[39m collate_fn)\n\u001b[1;32m      3\u001b[0m val_dl \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mCollateFn(return_raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m----> 5\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codes/nlp/araieval_arabicnlp24/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/codes/nlp/araieval_arabicnlp24/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/codes/nlp/araieval_arabicnlp24/venv/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 16\u001b[0m, in \u001b[0;36mCollateFn.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample, raw \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 16\u001b[0m     encodings\u001b[38;5;241m.\u001b[39mappend(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_raw:\n\u001b[1;32m     18\u001b[0m         raws\u001b[38;5;241m.\u001b[39mappend(raw)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'encoding'"
     ]
    }
   ],
   "source": [
    "collate_fn = CollateFn()\n",
    "train_dl = DataLoader(train_ds, batch_size=3, collate_fn = collate_fn)\n",
    "val_dl = DataLoader(val_ds, batch_size=3, collate_fn=CollateFn(return_raw=True))\n",
    "\n",
    "batch = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a4ea4c-181a-48cf-9fc0-4387bd47e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../task1\")\n",
    "\n",
    "from scorer import task1 as t1scorer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3fa8512-b3c1-4059-86c2-791b3bf880c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_output(objs):\n",
    "    labels_per_par = defaultdict(list)\n",
    "    for obj in objs:\n",
    "        par_id = obj[\"id\"]\n",
    "        labels = obj[\"labels\"]\n",
    "        labels_per_par[par_id] = t1scorer.process_labels(labels)\n",
    "    return labels_per_par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0a96884-bdca-48a3-8fc9-f207a86a916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label_encoding(text, encoding, label_encoding, labels):\n",
    "    span_objs = []\n",
    "    word_ids = encoding.word_ids()\n",
    "    for i, label in enumerate(labels):\n",
    "        flags = label_encoding[i]\n",
    "        span_ranges = find_consecutive_trues(flags)\n",
    "        for start_idx, end_idx in span_ranges:\n",
    "            start_word_id, end_word_id = word_ids[start_idx], word_ids[end_idx]\n",
    "            \n",
    "            if start_word_id is None or end_word_id is None:\n",
    "                # skip padding\n",
    "                continue\n",
    "                \n",
    "            (start_char_idx, _), (_, end_char_idx) = encoding.word_to_chars(\n",
    "                start_word_id\n",
    "            ), encoding.word_to_chars(end_word_id)\n",
    "\n",
    "            span_text=\"\"\n",
    "            if text is not None:\n",
    "                span_text = text[start_char_idx: end_char_idx]\n",
    "\n",
    "            obj = {\n",
    "                \"technique\": label,\n",
    "                \"start\": start_char_idx,\n",
    "                \"end\": end_char_idx,\n",
    "                \"text\": span_text,\n",
    "            }\n",
    "\n",
    "            span_objs.append(obj)\n",
    "    return span_objs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3742b667-31db-451f-a2b5-ab60ded1c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(batch, logits):\n",
    "    gold = format_for_output(batch['raws'])\n",
    "    hypotheses: List[Dict] = []\n",
    "    logits = logits.transpose(1, 2)\n",
    "    assert logits.size(1) == len(LABELS), \"expects the label in dim=1\"\n",
    "    \n",
    "    for i in range(logits.size(0)):\n",
    "        hypothesis = parse_label_encoding(None, batch['encodings'][i], logits[i], LABELS)\n",
    "        hypotheses.append({\n",
    "            \"id\": batch['raws'][i]['id'],\n",
    "            \"labels\": hypothesis\n",
    "        })\n",
    "        \n",
    "    hypotheses = format_for_output(hypotheses)\n",
    "    \n",
    "    res_for_screen, f1, f1_per_label = t1scorer.FLC_score_to_string(gold, hypotheses, per_label=True)\n",
    "    \n",
    "    metrics = {\n",
    "        'f1': f1,\n",
    "        **f1_per_label\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05777e90-adc2-4980-ab42-8a921590e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.037363604972837236,\n",
       " 'Appeal_to_Values': 0,\n",
       " 'Loaded_Language': 0.3448275862068965,\n",
       " 'Consequential_Oversimplification': 0,\n",
       " 'Causal_Oversimplification': 0,\n",
       " 'Questioning_the_Reputation': 0,\n",
       " 'Straw_Man': 0,\n",
       " 'Repetition': 0,\n",
       " 'Guilt_by_Association': 0,\n",
       " 'Appeal_to_Hypocrisy': 0,\n",
       " 'Conversation_Killer': 0,\n",
       " 'False_Dilemma-No_Choice': 0,\n",
       " 'Whataboutism': 0,\n",
       " 'Slogans': 0,\n",
       " 'Obfuscation-Vagueness-Confusion': 0,\n",
       " 'Name_Calling-Labeling': 0.29160803077211744,\n",
       " 'Flag_Waving': 0,\n",
       " 'Doubt': 0.22222222222222224,\n",
       " 'Appeal_to_Fear-Prejudice': 0,\n",
       " 'Exaggeration-Minimisation': 0,\n",
       " 'Red_Herring': 0,\n",
       " 'Appeal_to_Popularity': 0,\n",
       " 'Appeal_to_Authority': 0,\n",
       " 'Appeal_to_Time': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 0\n",
    "logits = torch.randn((3, MAX_LENGTH, len(LABELS)))\n",
    "logits = logits > THRESHOLD\n",
    "compute_metrics(batch, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4b2f6ea-2eda-4f61-b4ca-fe07f3da3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, checkpoint_dir):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    path = Path(checkpoint_dir) / \"model_best.pt\"\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict()\n",
    "        },\n",
    "        path,\n",
    "    )\n",
    "\n",
    "\n",
    "def validation(model, valid_dl, max_step):\n",
    "    model.eval()\n",
    "    loss_across_batches = []\n",
    "    metric_across_batches = dict(zip(['f1', ] + LABELS, [0.0, ] * 24))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(valid_dl, leave=False)\n",
    "        for step_no, batch in enumerate(bar):\n",
    "            for key in batch['tensors'].keys():\n",
    "                batch['tensors'][key] = batch['tensors'][key].to(device)\n",
    "            \n",
    "            # calculate loss on valid\n",
    "            loss, logits = step(model, batch['tensors'])\n",
    "            loss_across_batches.append(loss.item())\n",
    "\n",
    "            metrics = compute_metrics(batch, logits)\n",
    "            # sum up\n",
    "            for k, v in metrics.items():\n",
    "                metric_across_batches[k] += v\n",
    "\n",
    "            if step_no == max_step:\n",
    "                break\n",
    "\n",
    "        bar.close()\n",
    "\n",
    "        # we need the mean\n",
    "        for k,v in metric_across_batches.items():\n",
    "            metric_across_batches[k] /= (step_no + 1)\n",
    "\n",
    "    return {\"loss\": mean(loss_across_batches), **metric_across_batches}\n",
    "\n",
    "\n",
    "def step(model, batch):\n",
    "    del batch['offset_mapping']\n",
    "    output: TokenClassifierOutput = model(**batch)\n",
    "    return output['loss'], output['logits']\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    optimizer,\n",
    "    train_dl: torch.utils.data.DataLoader,\n",
    "    valid_dl: torch.utils.data.DataLoader,\n",
    "    config: dict,\n",
    "    args,\n",
    "    lr_scheduler=None,\n",
    "    checkpoint_dir=\"./checkpoint\",\n",
    "    max_step=-1,\n",
    "    experiment_name=None,\n",
    "    epoch=0,\n",
    "):\n",
    "\n",
    "    best_f1 = float(\"-inf\")\n",
    "\n",
    "    _training_history = {\n",
    "        \"train/loss\": [],\n",
    "        \"valid/loss\": [],\n",
    "        \"valid/f1\": []\n",
    "    }\n",
    "    _validation_history = {k:[] for k in LABELS}\n",
    "    history = {**_training_history, **_validation_history}\n",
    "\n",
    "    for epoch in range(epoch + 1, epoch + config[\"max_epoch\"] + 1):\n",
    "        model.train()\n",
    "        loss_across_batches = []\n",
    "        bar = tqdm(train_dl, unit=\"batch\")\n",
    "\n",
    "        for step_no, batch in enumerate(bar):\n",
    "            # move to gpu\n",
    "            for key in batch['tensors'].keys():\n",
    "                batch['tensors'][key] = batch['tensors'][key].to(device)\n",
    "        \n",
    "            # reset grads\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step forward\n",
    "            loss, logits = step(model, batch['tensors'])\n",
    "\n",
    "            # step backward\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_across_batches.append(loss.item())\n",
    "\n",
    "            # show each batch loss in tqdm bar\n",
    "            bar.set_postfix(**{\"loss\": loss.item()})\n",
    "        \n",
    "            # skip training on the entire training dataset\n",
    "            # useful during debugging\n",
    "            if step_no == max_step:\n",
    "                break\n",
    "\n",
    "        validation_metrics = validation(model, valid_dl, max_step)\n",
    "\n",
    "        history[\"train/loss\"].append(mean(loss_across_batches))\n",
    "        for k, v in validation_metrics.items():\n",
    "            history[f\"valid/{k}\"].append(v)\n",
    "\n",
    "        if validation_metrics[\"f1\"] > best_f1:\n",
    "            best_f1 = validation_metrics[\"f1\"]\n",
    "            save_checkpoint(model, optimizer, epoch, checkpoint_dir)\n",
    "            print(\"🎉 best f1 reached, saved a checkpoint.\")\n",
    "\n",
    "        log(epoch, history)\n",
    "\n",
    "\n",
    "\n",
    "def log(epoch, history, run, enable_neptune):\n",
    "    print(\n",
    "        f\"Epoch: {epoch},\\tTrain Loss: {history['loss/train'][-1]},\\tVal Loss: {history['loss/valid'][-1]}\\tVal F1: {history['pplx/valid'][-1]}\\tLR: {history['train/epoch/lr'][-1]}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path, optimizer=None, lr_scheduler=None):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler_state_dict\"])\n",
    "        epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "        logger.info(f\"🎉 Loaded existing model. Epoch: {checkpoint['epoch']}\")\n",
    "        return model, optimizer, lr_scheduler, epoch\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"No checkpoint found in the provided path\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed770b0-82ca-48d8-bcdd-312496128fb8",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ad32e73-1531-4e06-bcf1-1a084459253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    # For reproducibility\n",
    "    return CustomBertForTokenClassification.from_pretrained(MODEL_NAME, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22949d54-4788-4d9d-981a-2bdda6c086c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of CustomBertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|                                                                                  | 2/2333 [00:06<2:01:51,  3.14s/batch, loss=0.711]\n",
      "                                                                                                                                         \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 6\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 129\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, optimizer, train_dl, valid_dl, config, args, lr_scheduler, checkpoint_dir, max_step, experiment_name, epoch)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_no \u001b[38;5;241m==\u001b[39m max_step:\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m validation_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mean(loss_across_batches))\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m validation_metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[35], line 43\u001b[0m, in \u001b[0;36mvalidation\u001b[0;34m(model, valid_dl, max_step)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     42\u001b[0m     bar \u001b[38;5;241m=\u001b[39m tqdm(valid_dl, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step_no, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bar):\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensors\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     45\u001b[0m             batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensors\u001b[39m\u001b[38;5;124m'\u001b[39m][key] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensors\u001b[39m\u001b[38;5;124m'\u001b[39m][key]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/codes/nlp/araieval_arabicnlp24/venv/lib64/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/codes/nlp/araieval_arabicnlp24/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/codes/nlp/araieval_arabicnlp24/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/codes/nlp/araieval_arabicnlp24/venv/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 16\u001b[0m, in \u001b[0;36mCollateFn.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample, raw \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 16\u001b[0m     encodings\u001b[38;5;241m.\u001b[39mappend(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_raw:\n\u001b[1;32m     18\u001b[0m         raws\u001b[38;5;241m.\u001b[39mappend(raw)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'encoding'"
     ]
    }
   ],
   "source": [
    "model = model_init()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "config = {\n",
    "    'max_epoch': 2,\n",
    "}\n",
    "fit(model_init(), optimizer, train_dl, val_dl, config, None, max_step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233411bd-de34-4f74-8f02-34dd52d143d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
